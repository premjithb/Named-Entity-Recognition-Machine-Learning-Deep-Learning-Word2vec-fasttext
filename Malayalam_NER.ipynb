{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    read_file = open(path, 'r')\n",
    "    for line in read_file:\n",
    "        line = line.replace('\\n','')\n",
    "        items = line.split('\\t')\n",
    "        texts.append(items[0])\n",
    "        labels.append(items[1])\n",
    "    read_file.close()\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'NER_Malayalam.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = get_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [words]\n",
    "labels = set(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv = Word2Vec(words, size=300, window=1, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = np.shape(words)\n",
    "X = []\n",
    "for i in range(n):\n",
    "    X.append(model_wv.wv[words[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7059, 300) (7059,)\n",
      "(3026, 300) (3026,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(y_train))\n",
    "print(np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = SVC()\n",
    "#clf = KNeighborsClassifier(3)\n",
    "#clf = DecisionTreeClassifier(max_depth=5)\n",
    "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "#clf = MLPClassifier()\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.35\n",
      "Precision = 0.85\n",
      "Recall = 0.35\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {0:.2f}\".format(accuracy))\n",
    "print(\"Precision = {0:.2f}\".format(precision))\n",
    "print(\"Recall = {0:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ബിഗ് ബോസിൻറെ ആദ്യഭാഗം നവംബർ 2006 മുതൽ ജനുവരി 2007 വരെ ആണ് സംപ്രേഷണം ചെയ്തത് .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(tokens)):\n",
    "    test_data.append(model_wv.wv[tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['name', 'number', 'name', 'name', 'name', 'location', 'name',\n",
       "       'location', 'other', 'other', 'name', 'name', 'other'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = FastText()\n",
    "model_ft.skipgram(input='NER_Malayalam.txt', output='model_ft', epoch=10, lr=0.1, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(words[0])):\n",
    "    X.append(model_ft[words[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7059, 300) (7059,)\n",
      "(3026, 300) (3026,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(y_train))\n",
    "print(np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = SVC()\n",
    "clf = KNeighborsClassifier(3)\n",
    "#clf = DecisionTreeClassifier(max_depth=5)\n",
    "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "#clf = MLPClassifier()\n",
    "#clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.87\n",
      "Precision = 0.85\n",
      "Recall = 0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {0:.2f}\".format(accuracy))\n",
    "print(\"Precision = {0:.2f}\".format(precision))\n",
    "print(\"Recall = {0:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ബിഗ് ബോസിൻറെ ആദ്യഭാഗം നവംബർ 2006 മുതൽ ജനുവരി 2007 വരെ ആണ് സംപ്രേഷണം ചെയ്തത് .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(tokens)):\n",
    "    test_data.append(model_ft[tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'other', 'other', 'other', 'other', 'other', 'other',\n",
       "       'number', 'other', 'other', 'other', 'other', 'other'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'NER_Malayalam.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    read_file = open(path, 'r')\n",
    "    for line in read_file:\n",
    "        line = line.replace('\\n','')\n",
    "        if line == 'newline':\n",
    "            pass\n",
    "        else:\n",
    "            items = line.split('\\t')\n",
    "            texts.append(items[0])\n",
    "            labels.append(items[1])\n",
    "    read_file.close()\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = get_data(path)\n",
    "words = [words]\n",
    "wvmodel = Word2Vec(words, size=300, window=1, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(words[0])):\n",
    "    X.append(wvmodel.wv[words[0][i]])\n",
    "\n",
    "\n",
    "m, n = np.shape(X)\n",
    "X = np.reshape(X, (m,n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(tags)\n",
    "y = label_encoder.transform(tags)\n",
    "y = to_categorical(y, len(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                4352      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 4,649\n",
      "Trainable params: 4,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='tanh', input_shape = X_train.shape[1:]))\n",
    "model.add(Dense(9, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7059 samples, validate on 3026 samples\n",
      "Epoch 1/10\n",
      "7059/7059 [==============================] - 27s 4ms/step - loss: 0.9442 - acc: 0.8436 - val_loss: 0.6910 - val_acc: 0.8348\n",
      "Epoch 2/10\n",
      "7059/7059 [==============================] - 21s 3ms/step - loss: 0.6449 - acc: 0.8470 - val_loss: 0.6900 - val_acc: 0.8348\n",
      "Epoch 3/10\n",
      "7059/7059 [==============================] - 21s 3ms/step - loss: 0.6433 - acc: 0.8470 - val_loss: 0.6891 - val_acc: 0.8348\n",
      "Epoch 4/10\n",
      "7059/7059 [==============================] - 21s 3ms/step - loss: 0.6433 - acc: 0.8470 - val_loss: 0.6901 - val_acc: 0.8348\n",
      "Epoch 5/10\n",
      "7059/7059 [==============================] - 21s 3ms/step - loss: 0.6429 - acc: 0.8470 - val_loss: 0.6921 - val_acc: 0.8348\n",
      "Epoch 6/10\n",
      "7059/7059 [==============================] - 21s 3ms/step - loss: 0.6432 - acc: 0.8470 - val_loss: 0.6908 - val_acc: 0.8348\n",
      "Epoch 7/10\n",
      "7059/7059 [==============================] - 21s 3ms/step - loss: 0.6435 - acc: 0.8470 - val_loss: 0.6924 - val_acc: 0.8348\n",
      "Epoch 8/10\n",
      "7059/7059 [==============================] - 21s 3ms/step - loss: 0.6431 - acc: 0.8470 - val_loss: 0.6927 - val_acc: 0.8348\n",
      "Epoch 9/10\n",
      "7059/7059 [==============================] - 22s 3ms/step - loss: 0.6431 - acc: 0.8470 - val_loss: 0.6917 - val_acc: 0.8348\n",
      "Epoch 10/10\n",
      "7059/7059 [==============================] - 24s 3ms/step - loss: 0.6428 - acc: 0.8470 - val_loss: 0.6910 - val_acc: 0.8348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbd62b7470>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,  batch_size = batch_size, epochs = 10, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3026/3026 [==============================] - 2s 513us/step\n",
      "Accuracy =  83.47653669390706\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \",score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other' 'other' 'other' ... 'other' 'other' 'other']\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "pred_labels = le.inverse_transform(y_pred)\n",
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ബിഗ് ബോസിൻറെ ആദ്യഭാഗം നവംബർ 2006 മുതൽ ജനുവരി 2007 വരെ ആണ് സംപ്രേഷണം ചെയ്തത് .\"\n",
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "for i in range(len(tokens)):\n",
    "    test_data.append(wvmodel[tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt, nt = np.shape(test_data)\n",
    "test_data = np.reshape(test_data, (mt, nt,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other' 'other' 'other' 'other' 'other' 'other' 'other' 'other' 'other'\n",
      " 'other' 'other' 'other' 'other']\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(test_data)\n",
    "pred_labels = le.inverse_transform(y_pred)\n",
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
